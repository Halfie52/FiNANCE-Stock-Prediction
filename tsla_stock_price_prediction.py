# -*- coding: utf-8 -*-
"""TSLA Stock Price Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pq34BY2kiVqAm6HpkRqXNA3tMO-7E0xy
"""

import pandas as pd
import datetime
import pandas_datareader.data as web
from pandas import Series, DataFrame


start = datetime.datetime(2014, 9, 8)
end = datetime.datetime(2019, 9, 5)

df = web.DataReader("TSLA", 'yahoo', start, end)
df.tail()

#start code out the rolling mean

close_px = df['Adj Close']
mavg = close_px.rolling(window=100).mean()
mavg.tail(10)

# Commented out IPython magic to ensure Python compatibility.
#plotting out with Matplotlib. Overlay moving average with price chart

# %matplotlib inline
import matplotlib.pyplot as plt
from matplotlib import style

# Adjusting the size of matplotlib
import matplotlib as mpl
mpl.rc('figure', figsize=(8, 7))
mpl.__version__

# Adjusting the style of matplotlib
style.use('ggplot')

close_px.plot(label='TSLA')
mavg.plot(label='mavg')
plt.legend()

"""The expected return of a portfolio is calculated by multiplying the weight of each asset by its expected return and adding the values for each investment"""

returns = close_px / close_px.shift(1) - 1
returns.plot(label='return')

"""Above is the return deviation to determine risk and uncertainty

Now to analyse competitor stocks
"""

dfcomp = web.DataReader(['TSLA','NSANY', 'BMW.DE', 'VOW.DE', 'GM',
                         'HYMTF', 'F'],'yahoo',start=start,end=end)['Adj Close']

dfcomp.tail(10)

"""Correlation Analysis-If one competitor affects another"""

retscomp = dfcomp.pct_change()

corr = retscomp.corr()

corr

plt.scatter(retscomp.TSLA, retscomp.GM)
plt.xlabel('Returns TLSA')
plt.ylabel('Returns GM')

"""Further possible correlations:
KDE Kernel Density Estimate is a fundamental data smoothing problem when prediction are made about the population on finite sample data. Helps to generateestimations of the overall distributions
"""

from pandas.plotting import scatter_matrix

scatter_matrix(retscomp, diagonal='kde', figsize=(10, 10));

"""Now will use heat maps to visualize the correlation ranges among the competing stocks. The lighter the more correlated"""

plt.imshow(corr, cmap='hot', interpolation='none')
plt.colorbar()
plt.xticks(range(len(corr)), corr.columns)
plt.yticks(range(len(corr)), corr.columns);

"""Now analysing the stock's risks and returns"""

plt.scatter(retscomp.mean(), retscomp.std())
plt.xlabel('Expected returns')
plt.ylabel('Risk')
for label, x, y in zip(retscomp.columns, retscomp.mean(), retscomp.std()):
    plt.annotate(
        label, 
        xy = (x, y), xytext = (20, -20),
        textcoords = 'offset points', ha = 'right', va = 'bottom',
        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),
        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))

"""Predicting Stocks Price
Now will use three machine learning models to predict stock of TSLA:
1. Simple Linear Analysis 
2. Quadratic Discriminant Analysis(QDA)
3. K Nearest Neighbor(KNN)
"""

dfreg = df.loc[:,['Adj Close', 'Volume']]
dfreg['HL_PCT'] = (df['High'] -df['Low']) / df['Close'] * 100.0
dfreg['PCT_change'] = (df['Close'] - df['Open']) / df['Open'] * 100.0

dfreg.tail(6)

"""Pre-processing and cross validation

1. Drop missing value
2. Separating the label here, we want to predict the AdjClose
3. Scale the X so that everyone can have the same distribution for linear regression
4. Finally We want to find Data Series of late X and early X (train) for model generation and evaluation
5. Separate label and identify it as y
6. Separation of training and testing of model by cross validation train test split

Dovide the data into sets randomly , scikit learn provides a method called train_test_split
"""

import math
import numpy as np
import sklearn
from sklearn import preprocessing
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor

from sklearn.linear_model import Ridge
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split

# Drop missing value
dfreg.fillna(value=-99999, inplace=True)
# We want to separate 1 percent of the data to forecast
forecast_out = int(math.ceil(0.01 * len(dfreg)))
# Separating the label here, we want to predict the AdjClose
forecast_col = 'Adj Close'
dfreg['label'] = dfreg[forecast_col].shift(-forecast_out)
X = np.array(dfreg.drop(['label'], 1))
# Scale the X so that everyone can have the same distribution for linear regression
X = preprocessing.scale(X)
# Finally We want to find Data Series of late X and early X (train) for model generation and evaluation
X_lately = X[-forecast_out:]
X = X[:-forecast_out]
# Separate label and identify it as y
y = np.array(dfreg['label'])
y = y[:-forecast_out]

print('Dimension of X',X.shape)
print('Dimension of y',y.shape)


X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state = 5)


# Linear regression
clfreg = LinearRegression(n_jobs=-1)
clfreg.fit(X_train, y_train)
# Quadratic Regression 2
clfpoly2 = make_pipeline(PolynomialFeatures(2), Ridge())
clfpoly2.fit(X_train, y_train)

# Quadratic Regression 3
clfpoly3 = make_pipeline(PolynomialFeatures(3), Ridge())
clfpoly3.fit(X_train, y_train)

# KNN Regression
clfknn = KNeighborsRegressor(n_neighbors=2)
clfknn.fit(X_train, y_train)

"""Simple linear analysis and quadratic discriinant analysis

K nearest Neighbor
"""

# KNN Regression
clfknn = KNeighborsRegressor(n_neighbors=2)
clfknn.fit(X_train, y_train)

"""Evaluation"""

confidencereg = clfreg.score(X_test, y_test)
confidencepoly2 = clfpoly2.score(X_test,y_test)
confidencepoly3 = clfpoly3.score(X_test,y_test)
confidenceknn = clfknn.score(X_test, y_test)

forecast_set = clfreg.predict(X_lately)
dfreg['Forecast'] = np.nan

print(forecast_set,  forecast_out)



"""Plotting the Prediction"""

last_date = dfreg.iloc[-1].name
last_unix = last_date
next_unix = last_unix + datetime.timedelta(days=1)

for i in forecast_set:
    next_date = next_unix
    next_unix += datetime.timedelta(days=1)
    dfreg.loc[next_date] = [np.nan for _ in range(len(dfreg.columns)-1)]+[i]
dfreg['Adj Close'].tail(500).plot()
dfreg['Forecast'].tail(500).plot()
plt.legend(loc=4)
plt.xlabel('Date')
plt.ylabel('Price')
plt.show()